[2024-11-18T07:35:42.495+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_reddit_pipeline.reddit_extraction manual__2024-11-18T07:35:40.781363+00:00 [queued]>
[2024-11-18T07:35:42.503+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_reddit_pipeline.reddit_extraction manual__2024-11-18T07:35:40.781363+00:00 [queued]>
[2024-11-18T07:35:42.504+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-11-18T07:35:42.514+0000] {taskinstance.py:1382} INFO - Executing <Task(PythonOperator): reddit_extraction> on 2024-11-18 07:35:40.781363+00:00
[2024-11-18T07:35:42.519+0000] {standard_task_runner.py:57} INFO - Started process 92 to run task
[2024-11-18T07:35:42.522+0000] {standard_task_runner.py:84} INFO - Running: ['airflow', 'tasks', 'run', 'etl_reddit_pipeline', 'reddit_extraction', 'manual__2024-11-18T07:35:40.781363+00:00', '--job-id', '18', '--raw', '--subdir', 'DAGS_FOLDER/reddit_dag.py', '--cfg-path', '/tmp/tmpvc19tmxr']
[2024-11-18T07:35:42.525+0000] {standard_task_runner.py:85} INFO - Job 18: Subtask reddit_extraction
[2024-11-18T07:35:42.567+0000] {task_command.py:416} INFO - Running <TaskInstance: etl_reddit_pipeline.reddit_extraction manual__2024-11-18T07:35:40.781363+00:00 [running]> on host 9f42dd3b4e06
[2024-11-18T07:35:42.647+0000] {taskinstance.py:1662} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Bao Nguyen' AIRFLOW_CTX_DAG_ID='etl_reddit_pipeline' AIRFLOW_CTX_TASK_ID='reddit_extraction' AIRFLOW_CTX_EXECUTION_DATE='2024-11-18T07:35:40.781363+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-11-18T07:35:40.781363+00:00'
[2024-11-18T07:35:42.649+0000] {logging_mixin.py:151} WARNING - Version 7.7.1 of praw is outdated. Version 7.8.1 was released Friday October 25, 2024.
[2024-11-18T07:35:42.651+0000] {logging_mixin.py:151} INFO - connected to reddit!
[2024-11-18T07:35:43.198+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f8ee01d6fd0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'So my current thought is do a bit of both. If something has a fivetran connector, load it straight into Snowflake, but if doesn’t, load it to S3 then snow pipe it into snowflake.\n\nAny thoughts on this? Has anyone found loading straight into snowflake something they regret doing with an ingestion tool like fivetran? I’m thinking if you need to re-ingest data, or whatever else?\n\nWhen I’ve worked with warehouses like Redshift, I’ve ALWAYS loaded to S3 first, but it seems like loading straight into snowflake is the way a lot of people go.', 'author_fullname': 't2_lodwnfe3v', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Do you ingest to S3 or straight to snowflake?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1gt92wf', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.93, 'author_flair_background_color': 'transparent', 'subreddit_type': 'public', 'ups': 45, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': '980947cc-e787-11ed-87e3-ae81ee052dfe', 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 45, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1731831639.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>So my current thought is do a bit of both. If something has a fivetran connector, load it straight into Snowflake, but if doesn’t, load it to S3 then snow pipe it into snowflake.</p>\n\n<p>Any thoughts on this? Has anyone found loading straight into snowflake something they regret doing with an ingestion tool like fivetran? I’m thinking if you need to re-ingest data, or whatever else?</p>\n\n<p>When I’ve worked with warehouses like Redshift, I’ve ALWAYS loaded to S3 first, but it seems like loading straight into snowflake is the way a lot of people go.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': 'Principal Data Engineer', 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1gt92wf', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='General-Parsnip3138'), 'discussion_type': None, 'num_comments': 38, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': 'dark', 'permalink': '/r/dataengineering/comments/1gt92wf/do_you_ingest_to_s3_or_straight_to_snowflake/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1gt92wf/do_you_ingest_to_s3_or_straight_to_snowflake/', 'subreddit_subscribers': 229849, 'created_utc': 1731831639.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-11-18T07:35:43.199+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f8ee01d6fd0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "Context : I've joined service based company as data engineer. This company, basically does ROI ( some business process) for other company. It collected all the data about performance. And my team is supposed to make dashboards and fill missing values in columns. \n\n* Data is couple of excel files\n* No mention of ER Or Dimensional modeling\n* Manager already made dashboard, he's asking us to update it. \n* He doesn't know everything about the data. He's also learning about excel files and everything. \n* I am sitting with people who do the process and try to relate it with excel files. \n* It's extremely  hard to understand. Effecting my motivation to work. \n\nMy assumptions are : \n1) process is complex. Only people involved should make the data ? \n\n2) Data should be in dimensional model ? \n\n3) Data should be either relational databases or snowflake, not excel files ? \n\n4) If you didn't had proper model. Atleast document the meaning of each file, sheet, table, column and value ? \n\nIs this normal ? \nIsn't data modeling extremely important for long term benefits ? \n\nI was a student 3 months ago, all my assumptions are from textbook. \n", 'author_fullname': 't2_14arrf23be', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How common is shitty data? ', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1gtuyda', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.93, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 48, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 48, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': 1731911338.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1731898499.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Context : I&#39;ve joined service based company as data engineer. This company, basically does ROI ( some business process) for other company. It collected all the data about performance. And my team is supposed to make dashboards and fill missing values in columns. </p>\n\n<ul>\n<li>Data is couple of excel files</li>\n<li>No mention of ER Or Dimensional modeling</li>\n<li>Manager already made dashboard, he&#39;s asking us to update it. </li>\n<li>He doesn&#39;t know everything about the data. He&#39;s also learning about excel files and everything. </li>\n<li>I am sitting with people who do the process and try to relate it with excel files. </li>\n<li>It&#39;s extremely  hard to understand. Effecting my motivation to work. </li>\n</ul>\n\n<p>My assumptions are : \n1) process is complex. Only people involved should make the data ? </p>\n\n<p>2) Data should be in dimensional model ? </p>\n\n<p>3) Data should be either relational databases or snowflake, not excel files ? </p>\n\n<p>4) If you didn&#39;t had proper model. Atleast document the meaning of each file, sheet, table, column and value ? </p>\n\n<p>Is this normal ? \nIsn&#39;t data modeling extremely important for long term benefits ? </p>\n\n<p>I was a student 3 months ago, all my assumptions are from textbook. </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1gtuyda', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='TuneArchitect'), 'discussion_type': None, 'num_comments': 47, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1gtuyda/how_common_is_shitty_data/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1gtuyda/how_common_is_shitty_data/', 'subreddit_subscribers': 229849, 'created_utc': 1731898499.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-11-18T07:35:43.200+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f8ee01d6fd0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "I was talking to a data engineer about their work experience and they mentioned that they use databricks+snowflake. And that they are migrating from on Prem informatica flows to databricks. \n\nHow common is this pattern? I don't see a reason for paying for both databricks and snowflake? Couldn't they have done it directly in databricks \n\nAre they bluffing current experience or is this a commonly (or rarely) used patten I'm not aware of\n\n\nI suppose if they're doing the heavy transformation on databricks, they wouldn't have to setup snowflake with a higher amount of compute or am I wrong? Never worked with snowflake", 'author_fullname': 't2_jcm6z7av', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': "Someone said they're using Databricks + Snowflake in their proj", 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1gtnqff', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.94, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 37, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 37, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': 1731877936.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1731877733.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I was talking to a data engineer about their work experience and they mentioned that they use databricks+snowflake. And that they are migrating from on Prem informatica flows to databricks. </p>\n\n<p>How common is this pattern? I don&#39;t see a reason for paying for both databricks and snowflake? Couldn&#39;t they have done it directly in databricks </p>\n\n<p>Are they bluffing current experience or is this a commonly (or rarely) used patten I&#39;m not aware of</p>\n\n<p>I suppose if they&#39;re doing the heavy transformation on databricks, they wouldn&#39;t have to setup snowflake with a higher amount of compute or am I wrong? Never worked with snowflake</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1gtnqff', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='gcrfrtxmooxnsmj'), 'discussion_type': None, 'num_comments': 23, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1gtnqff/someone_said_theyre_using_databricks_snowflake_in/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1gtnqff/someone_said_theyre_using_databricks_snowflake_in/', 'subreddit_subscribers': 229849, 'created_utc': 1731877733.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-11-18T07:35:43.200+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f8ee01d6fd0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'I am currently learning and going through all the concepts.  So currently Is that my data model understanding incorrect? \n\nSuppose if record is changed 3 times,   SCD 2 store all 3 and SCD 3 will store  current and last change', 'author_fullname': 't2_3yzltsu8', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'I thought SCD 2 modeling store all history versions and SCD 3 store only current and previous history?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1gta7ei', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.92, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 16, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 16, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1731836787.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I am currently learning and going through all the concepts.  So currently Is that my data model understanding incorrect? </p>\n\n<p>Suppose if record is changed 3 times,   SCD 2 store all 3 and SCD 3 will store  current and last change</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1gta7ei', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Dead-Shot1'), 'discussion_type': None, 'num_comments': 16, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1gta7ei/i_thought_scd_2_modeling_store_all_history/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1gta7ei/i_thought_scd_2_modeling_store_all_history/', 'subreddit_subscribers': 229849, 'created_utc': 1731836787.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-11-18T07:35:43.201+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f8ee01d6fd0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hi friends! I’ve been a data engineer for around 4-5 years now and recently started a new position. The tile is also DE, but I’m realizing I might be dabbling in the platform engineering world (esp given we were formed from the Platform team).\n\nFor example, I’m not only building pipelines and managing our Snowflake instance, but also doing lots of terraform via RBAC, managing apps via ArgoCD, and doing package version updates on our repo.\n\nWould anybody be able to help me better understand how a DE might differentiate from a Platform engineer vs a devops engineer? And would those future paths might look like? It feels like platform engineering might open me up to more opportunities, but I’m not exactly sure how the work differs. For context, I came up from being a DA -> DE.', 'author_fullname': 't2_u7xhpn', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Data engineering vs Platform engineering ', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1gtkbsv', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.94, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 16, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 16, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': 1731869186.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1731868749.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hi friends! I’ve been a data engineer for around 4-5 years now and recently started a new position. The tile is also DE, but I’m realizing I might be dabbling in the platform engineering world (esp given we were formed from the Platform team).</p>\n\n<p>For example, I’m not only building pipelines and managing our Snowflake instance, but also doing lots of terraform via RBAC, managing apps via ArgoCD, and doing package version updates on our repo.</p>\n\n<p>Would anybody be able to help me better understand how a DE might differentiate from a Platform engineer vs a devops engineer? And would those future paths might look like? It feels like platform engineering might open me up to more opportunities, but I’m not exactly sure how the work differs. For context, I came up from being a DA -&gt; DE.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1gtkbsv', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='cuhristophet'), 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1gtkbsv/data_engineering_vs_platform_engineering/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1gtkbsv/data_engineering_vs_platform_engineering/', 'subreddit_subscribers': 229849, 'created_utc': 1731868749.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-11-18T07:35:43.201+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f8ee01d6fd0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Saw this chart in Hamilton documentation and wondered if this is common terminology for the layers of data stack, more specifically: \n\n1. Is there really "asset level"? Is dbt "asset level"? \n2. What is good source to read about these layers? \n3. Why *** is data and DuckDB is execution? Ok to have Snofkake on two levels? Is lang chain same level as pandas? ', 'author_fullname': 't2_dukebon2', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How accurate are these layer definitions from Hamilton? ', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': 86, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1gtp9qn', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'ups': 14, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': True, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 14, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/uex5kcoI6GcNgi3z7rK7J7qoTRc7jJ_dE0IlYagXBsg.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'image', 'content_categories': None, 'is_self': False, 'subreddit_type': 'public', 'created': 1731881780.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'i.redd.it', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Saw this chart in Hamilton documentation and wondered if this is common terminology for the layers of data stack, more specifically: </p>\n\n<ol>\n<li>Is there really &quot;asset level&quot;? Is dbt &quot;asset level&quot;? </li>\n<li>What is good source to read about these layers? </li>\n<li>Why *** is data and DuckDB is execution? Ok to have Snofkake on two levels? Is lang chain same level as pandas? </li>\n</ol>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://i.redd.it/4pwmfckpdj1e1.png', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://preview.redd.it/4pwmfckpdj1e1.png?auto=webp&s=cd84dcf3e43d5223404d5563e377a4941a8bc4d0', 'width': 1080, 'height': 669}, 'resolutions': [{'url': 'https://preview.redd.it/4pwmfckpdj1e1.png?width=108&crop=smart&auto=webp&s=e9428c9b1aab76dc4fd6d756682f723f403f974d', 'width': 108, 'height': 66}, {'url': 'https://preview.redd.it/4pwmfckpdj1e1.png?width=216&crop=smart&auto=webp&s=4a1da10562802538ba8bbf96dfe47214a6eacca8', 'width': 216, 'height': 133}, {'url': 'https://preview.redd.it/4pwmfckpdj1e1.png?width=320&crop=smart&auto=webp&s=493730893e1c73434dbde2776a9c32f420f8c307', 'width': 320, 'height': 198}, {'url': 'https://preview.redd.it/4pwmfckpdj1e1.png?width=640&crop=smart&auto=webp&s=b9a601cc199382d8f4e6fac7975dd55f5ba496f7', 'width': 640, 'height': 396}, {'url': 'https://preview.redd.it/4pwmfckpdj1e1.png?width=960&crop=smart&auto=webp&s=4c123c9e56c262cd7ba03e26d89b17470524cc4a', 'width': 960, 'height': 594}, {'url': 'https://preview.redd.it/4pwmfckpdj1e1.png?width=1080&crop=smart&auto=webp&s=3b10cf00c5baa593a7dfce8aa34d78c079768c09', 'width': 1080, 'height': 669}], 'variants': {}, 'id': 'azLc1WtS87VcdtpBIu6XDjPjH6_HVWFlqBn3ifp3n3w'}], 'enabled': True}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'mod_note': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'num_reports': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1gtp9qn', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='iamevpo'), 'discussion_type': None, 'num_comments': 8, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1gtp9qn/how_accurate_are_these_layer_definitions_from/', 'stickied': False, 'url': 'https://i.redd.it/4pwmfckpdj1e1.png', 'subreddit_subscribers': 229849, 'created_utc': 1731881780.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-11-18T07:35:43.202+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f8ee01d6fd0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "and when I'm talking small I mean pretty much startup sized. Like 1 DE, 1 Analyst and a handful of DE contractors handling small scale data (< 5 TB total in data warehouse, < 500k rows refreshing/inserting daily). Our main deliverable is a set of about two dozen operational dashboards that need to be refreshed daily in the early morning - no ML, IoT stuff or other data products.\n\nA little background - I inherited some tech debt (no documentation, no peers) coming into my role as a data engineer in a manufacturing company \\~2.5 years ago. It's taken me about that long to understand how messy everything truly is, and that we need to migrate or get stuck here for the foreseeable future. \n\nOur analytics platform is a garbled mess of on-prem SSIS and Azure Data Factory pipelines that kick off Databricks notebooks (medallion). From there, we ultimately write to a Synapse Dedicated SQL Pool where finally all the business logic is baked into sql views (sometimes nested). I'm skipping a bunch of steps but the databricks component is essentially useless and the SSIS jobs are overly complex, so we're looking to start over from scratch and minimize or at least optimize costs. If you're asking how we got here I'm not sure either. Probably a mix of mismanagement and contractor turnover.  \n\n\nWhat solutions have worked for your smaller sized teams? My manager is leaning towards Fivetran + Fabric which I am surprisingly not super against given how out of the box things look in there. Fivetran would handle the CDC from our ERP to Azure Data Lake and Fabric would pick up from there. I realize the inherent risk with how new Fabric is, but it kind of sounds up our alley. I have a ton of users in Power BI looking to upload their own spreadsheets to existing reports, and Fabric seems to make managing that easy.\n\nOur most complicated data sources are a few third-party REST APIs, so if I could slim our pipelines down to just Fabric pipelines + a few Spark jobs and migrate the Synapse view logic over to the Fabric Lakehouses I think we would be set. Curious to hear what other smaller teams are using.", 'author_fullname': 't2_epglc', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'What are some viable platforms for smaller DE teams?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1gtvrtn', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 12, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 12, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1731901165.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>and when I&#39;m talking small I mean pretty much startup sized. Like 1 DE, 1 Analyst and a handful of DE contractors handling small scale data (&lt; 5 TB total in data warehouse, &lt; 500k rows refreshing/inserting daily). Our main deliverable is a set of about two dozen operational dashboards that need to be refreshed daily in the early morning - no ML, IoT stuff or other data products.</p>\n\n<p>A little background - I inherited some tech debt (no documentation, no peers) coming into my role as a data engineer in a manufacturing company ~2.5 years ago. It&#39;s taken me about that long to understand how messy everything truly is, and that we need to migrate or get stuck here for the foreseeable future. </p>\n\n<p>Our analytics platform is a garbled mess of on-prem SSIS and Azure Data Factory pipelines that kick off Databricks notebooks (medallion). From there, we ultimately write to a Synapse Dedicated SQL Pool where finally all the business logic is baked into sql views (sometimes nested). I&#39;m skipping a bunch of steps but the databricks component is essentially useless and the SSIS jobs are overly complex, so we&#39;re looking to start over from scratch and minimize or at least optimize costs. If you&#39;re asking how we got here I&#39;m not sure either. Probably a mix of mismanagement and contractor turnover.  </p>\n\n<p>What solutions have worked for your smaller sized teams? My manager is leaning towards Fivetran + Fabric which I am surprisingly not super against given how out of the box things look in there. Fivetran would handle the CDC from our ERP to Azure Data Lake and Fabric would pick up from there. I realize the inherent risk with how new Fabric is, but it kind of sounds up our alley. I have a ton of users in Power BI looking to upload their own spreadsheets to existing reports, and Fabric seems to make managing that easy.</p>\n\n<p>Our most complicated data sources are a few third-party REST APIs, so if I could slim our pipelines down to just Fabric pipelines + a few Spark jobs and migrate the Synapse view logic over to the Fabric Lakehouses I think we would be set. Curious to hear what other smaller teams are using.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1gtvrtn', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='epichicken'), 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1gtvrtn/what_are_some_viable_platforms_for_smaller_de/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1gtvrtn/what_are_some_viable_platforms_for_smaller_de/', 'subreddit_subscribers': 229849, 'created_utc': 1731901165.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-11-18T07:35:43.202+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f8ee01d6fd0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Given the assumption of a logical (not necessarily physical) star schema, what\'s your go to approach for modeling "current" Calculated Facts about a domain entity (dimension)?\n\nUse Case: a rating about a persistent entity (e.g., customer, HR, supplier) that is based on a calculation of events (facts), but you want to be able to use/compare.\n\nExample: customer value is based on total spend / total purchases. You can just leave the elements of the fact table and in some layer (a view, semantic layer, etc.), but this value is more of a property of the dimension (the customer\'s value) - it doesn\'t really map to the other facts at the grain, because another fact at the grain is about that event.', 'author_fullname': 't2_ahf8v', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[DW/Star] Locating "Current" Calculated Facts in the Model', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1gtjvxr', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 9, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 9, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1731867589.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Given the assumption of a logical (not necessarily physical) star schema, what&#39;s your go to approach for modeling &quot;current&quot; Calculated Facts about a domain entity (dimension)?</p>\n\n<p>Use Case: a rating about a persistent entity (e.g., customer, HR, supplier) that is based on a calculation of events (facts), but you want to be able to use/compare.</p>\n\n<p>Example: customer value is based on total spend / total purchases. You can just leave the elements of the fact table and in some layer (a view, semantic layer, etc.), but this value is more of a property of the dimension (the customer&#39;s value) - it doesn&#39;t really map to the other facts at the grain, because another fact at the grain is about that event.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1gtjvxr', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='PencilBoy99'), 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1gtjvxr/dwstar_locating_current_calculated_facts_in_the/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1gtjvxr/dwstar_locating_current_calculated_facts_in_the/', 'subreddit_subscribers': 229849, 'created_utc': 1731867589.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-11-18T07:35:43.203+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f8ee01d6fd0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "I am in the process of creating a data lake for my Apple Health data. In my case I believe the API data available extends to the very first observation records. The data lake is a necessity because the alternative is requesting the XML file from apple each time you want to see updates. However as a theoretical matter I was wondering if something like GDPR had an impact on what was available and there was a mix of data stored in an existing database containing the oldest historical records and the API for which streaming data  was ingested but which did not have the oldest records. Most dags I see involve partitioning by date and storage as parquet. This is all automated. Can you drag and drop into these folders? Should you instead create a new pipeline and scripts for one time ingestion of historical records? It seems there are not clear answers to questions like this. Everything seems so tailored to the exact specification of the example that I can't find general answers", 'author_fullname': 't2_gyj3b', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Can backfill be accomplished by simply dragging and dropping some files or does it need to follow the same pipeline of streaming real time data', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1gtauzp', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.76, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 4, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 4, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1731839661.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I am in the process of creating a data lake for my Apple Health data. In my case I believe the API data available extends to the very first observation records. The data lake is a necessity because the alternative is requesting the XML file from apple each time you want to see updates. However as a theoretical matter I was wondering if something like GDPR had an impact on what was available and there was a mix of data stored in an existing database containing the oldest historical records and the API for which streaming data  was ingested but which did not have the oldest records. Most dags I see involve partitioning by date and storage as parquet. This is all automated. Can you drag and drop into these folders? Should you instead create a new pipeline and scripts for one time ingestion of historical records? It seems there are not clear answers to questions like this. Everything seems so tailored to the exact specification of the example that I can&#39;t find general answers</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1gtauzp', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='sumant28'), 'discussion_type': None, 'num_comments': 3, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1gtauzp/can_backfill_be_accomplished_by_simply_dragging/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1gtauzp/can_backfill_be_accomplished_by_simply_dragging/', 'subreddit_subscribers': 229849, 'created_utc': 1731839661.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-11-18T07:35:43.203+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f8ee01d6fd0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'We’re planning a data migration for our core banking system, but I want to ensure the strategy is rock-solid. Does anyone have experience with data migration in banking, especially with core banking systems in New Zealand? Any tips or best practices?', 'author_fullname': 't2_19flwxil3h', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Help with Data Migration Strategy for Core Banking Systems', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': True, 'name': 't3_1gty17o', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1731909136.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>We’re planning a data migration for our core banking system, but I want to ensure the strategy is rock-solid. Does anyone have experience with data migration in banking, especially with core banking systems in New Zealand? Any tips or best practices?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1gty17o', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='strict_princess08'), 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1gty17o/help_with_data_migration_strategy_for_core/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1gty17o/help_with_data_migration_strategy_for_core/', 'subreddit_subscribers': 229849, 'created_utc': 1731909136.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-11-18T07:35:43.203+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f8ee01d6fd0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "Hi all,\n\nI am reaching out to ask if there are any services or solutions recommended for dependency mapping for tables. At my current company we have a very disorganised data warehouse where scheduled queries are being used alongside airflow to schedule queries and we're running into issues where table\\_a is being affected by table\\_z but there is about 20 tables in between those two, there isn't any documentation for this due to hasty growth and development and between repetitive code and accidental knock on effects we are becoming increasingly inefficient and error prone.  I am reaching out to ask if there is any software that anyone has used before to remediate this and essentially provide mapping for tables to help us reduce repetition and understand the data flow more?\n\n  \nThanks", 'author_fullname': 't2_mfug7', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Dependency mapping for tables ?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1gtkvzb', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1731870222.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hi all,</p>\n\n<p>I am reaching out to ask if there are any services or solutions recommended for dependency mapping for tables. At my current company we have a very disorganised data warehouse where scheduled queries are being used alongside airflow to schedule queries and we&#39;re running into issues where table_a is being affected by table_z but there is about 20 tables in between those two, there isn&#39;t any documentation for this due to hasty growth and development and between repetitive code and accidental knock on effects we are becoming increasingly inefficient and error prone.  I am reaching out to ask if there is any software that anyone has used before to remediate this and essentially provide mapping for tables to help us reduce repetition and understand the data flow more?</p>\n\n<p>Thanks</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1gtkvzb', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='UnlovedMisfit'), 'discussion_type': None, 'num_comments': 6, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1gtkvzb/dependency_mapping_for_tables/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1gtkvzb/dependency_mapping_for_tables/', 'subreddit_subscribers': 229849, 'created_utc': 1731870222.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-11-18T07:35:43.204+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f8ee01d6fd0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hey guys I’m dealing with rhapsody integration from one hospital to another and we want to enable mTLS \n\nLong shot but has anyone done this? ', 'author_fullname': 't2_45fkds58', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Rhapsody | mTLS', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1gtuvla', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1731898245.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hey guys I’m dealing with rhapsody integration from one hospital to another and we want to enable mTLS </p>\n\n<p>Long shot but has anyone done this? </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1gtuvla', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='4EVR20'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1gtuvla/rhapsody_mtls/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1gtuvla/rhapsody_mtls/', 'subreddit_subscribers': 229849, 'created_utc': 1731898245.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-11-18T07:35:43.204+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f8ee01d6fd0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hi people,\n\nI am a data engineer working in a small team with 2 other engineers and a manager who is also the project manager. My questions are:\n\nHow are your data projects planned? Who planned the work items (is it the responsibility of the engineer)? How detailed the work items and time estimation should be before you can start the projects? How long does it take from drafting the planning to starting the coding?\n\nI am curious because I have recently started working on project planning and technical design of a new project. My manager is not satisfied with my planning and estimation on the level of "build a manual input table of xxx data" and they wants me to specify all the details such as the columns I need to build for this manual input table. My gut told me it\'s not agile but I\'ve never worked with a well-structured project team and I wonder what\'s the industry standard for a project to start.\n\nI did a big project this year when my manager was not involved so there was not this "specifying on columns" requirement at that time. I personally am more comfortable with the method of having a high-level design and then just starting to code, then figuring out what are the specific requirements along the way but I am open to different opinions!', 'author_fullname': 't2_8604br4k', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How do your data projects get planned?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1gtrgqg', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1731887952.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hi people,</p>\n\n<p>I am a data engineer working in a small team with 2 other engineers and a manager who is also the project manager. My questions are:</p>\n\n<p>How are your data projects planned? Who planned the work items (is it the responsibility of the engineer)? How detailed the work items and time estimation should be before you can start the projects? How long does it take from drafting the planning to starting the coding?</p>\n\n<p>I am curious because I have recently started working on project planning and technical design of a new project. My manager is not satisfied with my planning and estimation on the level of &quot;build a manual input table of xxx data&quot; and they wants me to specify all the details such as the columns I need to build for this manual input table. My gut told me it&#39;s not agile but I&#39;ve never worked with a well-structured project team and I wonder what&#39;s the industry standard for a project to start.</p>\n\n<p>I did a big project this year when my manager was not involved so there was not this &quot;specifying on columns&quot; requirement at that time. I personally am more comfortable with the method of having a high-level design and then just starting to code, then figuring out what are the specific requirements along the way but I am open to different opinions!</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1gtrgqg', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Formal-Big-6794'), 'discussion_type': None, 'num_comments': 3, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1gtrgqg/how_do_your_data_projects_get_planned/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1gtrgqg/how_do_your_data_projects_get_planned/', 'subreddit_subscribers': 229849, 'created_utc': 1731887952.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-11-18T07:35:43.205+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f8ee01d6fd0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'How do you guys do live data quality test on Databricks pipeline while running the pipeline?\nI’d like to check if the fields of incoming data source/files haven’t changed and the count of the records is not abnormally high or low', 'author_fullname': 't2_j4gk8ydx', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Live DQ test on Databricks', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1gtq2nm', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1731884006.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>How do you guys do live data quality test on Databricks pipeline while running the pipeline?\nI’d like to check if the fields of incoming data source/files haven’t changed and the count of the records is not abnormally high or low</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1gtq2nm', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='CuriousSwitch7268'), 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1gtq2nm/live_dq_test_on_databricks/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1gtq2nm/live_dq_test_on_databricks/', 'subreddit_subscribers': 229849, 'created_utc': 1731884006.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-11-18T07:35:43.205+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f8ee01d6fd0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'I’m building a schedule with my wife. We need one because we both have careers and young kids, so time escapes us rather easily. It’s often enough that we try to squeeze in a little time for ourselves to watch TV throughout the week, and end the week feeling like nothing has been accomplished professionally. So a schedule will be introduced, to hopefully help give us some balance.\n\nThe thing is, sometimes I work from home after hours because some things need to get done. I’m a new employee where I work also, so I don’t want to be applying time constraint pushbacks too much. The thing is, our schedule currently calls this time my “work time.”\n\nI asked, well, what about professional development time? Time to focus on things I want, like open source software that I want to develop? Or a homelab? Or a personal knowledge base? Anything that I want to develop for my own personal interests… what of my own personal hobby coding and professional development?\n\nThese times are blended in the schedule. My wife says they’re the same thing and don’t need to be differentiated. Personally though, I believe they’re very different. One’s relaxing, and one can be quite stressful. One is for pay, and the other has no tangible immediate return. One is for my boss, the other is for me. Evidence of one disappears after I lose my job, but the other stays with me forever. Surely these aren’t the “same thing,” right?\n\nAm I wrong here?', 'author_fullname': 't2_uqm6fk35', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Making schedules with my wife… should I blend my professional development time with my work from home time?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1gtmwnj', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.31, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1731875551.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I’m building a schedule with my wife. We need one because we both have careers and young kids, so time escapes us rather easily. It’s often enough that we try to squeeze in a little time for ourselves to watch TV throughout the week, and end the week feeling like nothing has been accomplished professionally. So a schedule will be introduced, to hopefully help give us some balance.</p>\n\n<p>The thing is, sometimes I work from home after hours because some things need to get done. I’m a new employee where I work also, so I don’t want to be applying time constraint pushbacks too much. The thing is, our schedule currently calls this time my “work time.”</p>\n\n<p>I asked, well, what about professional development time? Time to focus on things I want, like open source software that I want to develop? Or a homelab? Or a personal knowledge base? Anything that I want to develop for my own personal interests… what of my own personal hobby coding and professional development?</p>\n\n<p>These times are blended in the schedule. My wife says they’re the same thing and don’t need to be differentiated. Personally though, I believe they’re very different. One’s relaxing, and one can be quite stressful. One is for pay, and the other has no tangible immediate return. One is for my boss, the other is for me. Evidence of one disappears after I lose my job, but the other stays with me forever. Surely these aren’t the “same thing,” right?</p>\n\n<p>Am I wrong here?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1gtmwnj', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='DuckDatum'), 'discussion_type': None, 'num_comments': 14, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1gtmwnj/making_schedules_with_my_wife_should_i_blend_my/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1gtmwnj/making_schedules_with_my_wife_should_i_blend_my/', 'subreddit_subscribers': 229849, 'created_utc': 1731875551.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-11-18T07:35:43.219+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-11-18T07:35:43.229+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=etl_reddit_pipeline, task_id=reddit_extraction, execution_date=20241118T073540, start_date=20241118T073542, end_date=20241118T073543
[2024-11-18T07:35:43.246+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-11-18T07:35:43.262+0000] {taskinstance.py:2778} INFO - 0 downstream tasks scheduled from follow-on schedule check
